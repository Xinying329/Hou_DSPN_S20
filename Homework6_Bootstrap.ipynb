{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: \n",
    "\n",
    "**DUE:** 5pm EST, April 9, 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Conceptual:** Short answer questions. Be concise\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Let us consider the \"curse of dimensionality\" (i.e., when the ratio of predictor variables, p, to observations, n, is high) in the context of kNN. Answer the following:\n",
    "\n",
    "<br>\n",
    "\n",
    "(a) Suppose that we have a set of observations, each with measurements on p = 1 feature, X. We assume that X is uniformly (evenly) distributed between 0 and 1. Associated with each observation is a response value. Suppose that we wish to predict a test observation’s response using only observations that are within 10% of the range of X closest to that test observation. For instance, in order to predict the response for a test observation with X = 0.6, we will use observations in the range [0.55,0.65]. On average, what fraction of the available observations will we use to make the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "10%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Suppose that we have a set of observations, each with measurements on p = 2 features, X1 and X2. We assume that (X1,X2) are uniformly distributed between 0 and 1. We wish to predict a test observation’s response using only observations that are within 10% of the range of X1 and within 10% of the range of X2 closest to that test observation. For instance, in order to predict the response for a test observation with X1 = 0.6 and X2 = 0.35, we will use observations in the range [0.55, 0.65] for X1 and in the range [0.3, 0.4] for X2. On average, what fraction of the available observations will we use to make the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)  Using your answers to parts (a)–(c), argue that a drawback of KNN when p is large is that there are very few training observations “near” any given test observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "By number of independent variables, available observations near the test observation decreases exponentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "2. Explain how k-fold cross-validation is implemented. What are the advantages and disadvantages of k-fold cross-validation relative to LOOCV?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "K-fold cross-validation randomly divides the set of observations into k groups. The first fold is treated as a validation set, and the method is fit on the remaining k-1 folds. \n",
    "<br>This procedure is repeated k times; each time, a different group of observations is treated as a validation set.</br>\n",
    "- Advantages: K-fold CV gives more accurate estimates of the test error rate than LOOCV.\n",
    "- Disadvantages: LOOCV tends to has less bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "3. Differentiate the bootstrap from a permutation test. Describe each and when is it appropriate to each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "- Bootstrap: Eestimates the variability of the sampling process and works well for estimating confidence intervals. \n",
    "- Permutation test: Test a specific null hypothesis like T-test or ANOVA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Applied:** Show your code & plots\n",
    "\n",
    "We will use both datasets from the HCP dataset for these problems. Include conceptual answers to questions as comments in code cells. You should use the tidyverse and class libraries for this assignment, as well as the data table for the HCP data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use kNN to build a classifier that for predicting Gender using the unadjusted Flanker task performance (Flanker_unadj). \n",
    "\n",
    "(a) Split the data set up into 1006 training observations and 200 test observations. Clasffiy using kNN with k = 5. Show your classification accuracy as a predicted vs. observed table, and report the mean classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        y_test\n",
       "knn_pred  F  M\n",
       "       F 74 41\n",
       "       M 41 44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.59"
      ],
      "text/latex": [
       "0.59"
      ],
      "text/markdown": [
       "0.59"
      ],
      "text/plain": [
       "[1] 0.59"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Question 4\n",
    "# -------------------------------\n",
    "df <- read.csv(\"hcp_data/unrestricted_trimmed_1_7_2020_10_50_44.csv\")\n",
    "library(tidyverse)\n",
    "df <- df %>% select(Subject,Gender,Flanker_Unadj) \n",
    "df <- df %>% na.omit() \n",
    "# (a)\n",
    "id <- sample(nrow(df),200)\n",
    "X_test <- df[id,3]\n",
    "y_test <- df[id,2]\n",
    "X_train <- df[-id,3]\n",
    "y_train <- df[-id,2]\n",
    "\n",
    "library(class)\n",
    "knn_pred <- knn(data.frame(X_train),data.frame(X_test),cl = y_train,k=5)\n",
    "table(knn_pred,y_test)\n",
    "mean(knn_pred == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Now repeat your analysis using a range of k's, from 1-100. Plot the performance of the classifier (i.e., accuracy) for each value of k. Which value gives you the highest accuracy and what is the accuracy for that best k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "k_range = rep(0,100)\n",
    "for (i in 1:100){\n",
    "    knn_pred <- knn(data.frame(X_train),data.frame(X_test),cl = y_train,k=i)\n",
    "    k_range[i] = mean(knn_pred == y_test)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "2"
      ],
      "text/latex": [
       "2"
      ],
      "text/markdown": [
       "2"
      ],
      "text/plain": [
       "[1] 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.605"
      ],
      "text/latex": [
       "0.605"
      ],
      "text/markdown": [
       "0.605"
      ],
      "text/plain": [
       "[1] 0.605"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "which.max(k_range)\n",
    "k_range[which.max(k_range)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
